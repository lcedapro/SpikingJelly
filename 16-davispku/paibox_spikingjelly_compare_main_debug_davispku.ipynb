{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\oilgi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\paibox\\components\\synapses\\transforms.py:103: AutoOptimizationWarning: dtype of weight is optimized automatically, int32 -> int8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# paibox 和 spikingjelly 的推理结果比较，输出为 csv 文件\n",
    "# 需要修改数据集路径DVS128GESTURE_DATA_DIR\n",
    "import torch\n",
    "import numpy as np\n",
    "import paibox as pb\n",
    "import csv\n",
    "\n",
    "# PAIBox网络定义\n",
    "class Conv2d_Net(pb.Network):\n",
    "    def __init__(self, channels, param_dict):\n",
    "        super().__init__()\n",
    "\n",
    "        self.i0 = pb.InputProj(input=None, shape_out=(2, 69, 52))\n",
    "        self.n0 = pb.LIF((channels*2, 35, 26), bias=param_dict['conv.0.bias'], threshold=param_dict['conv.0.vthr'], reset_v=0, tick_wait_start=1) # convpool3x3\n",
    "        self.conv2d_0 = pb.Conv2d(self.i0, self.n0, kernel=param_dict['conv.0.weight'], padding=2, stride=2)\n",
    "\n",
    "        self.n1 = pb.LIF((channels*2, 35, 26), bias=param_dict['conv.2.bias'], threshold=param_dict['conv.2.vthr'], reset_v=0, tick_wait_start=2) # conv3x3\n",
    "        self.conv2d_1 = pb.Conv2d(self.n0, self.n1, kernel=param_dict['conv.2.weight'], padding=2, stride=1)\n",
    "\n",
    "        self.n2 = pb.LIF((channels*4, 18, 13), bias=param_dict['conv.4.bias'], threshold=param_dict['conv.4.vthr'], reset_v=0, tick_wait_start=3) # convpool3x3\n",
    "        self.conv2d_2 = pb.Conv2d(self.n1, self.n2, kernel=param_dict['conv.4.weight'], padding=2, stride=2)\n",
    "\n",
    "        self.n3 = pb.LIF((channels*4, 18, 13), bias=param_dict['conv.6.bias'], threshold=param_dict['conv.6.vthr'], reset_v=0, tick_wait_start=4) # conv3x3\n",
    "        self.conv2d_3 = pb.Conv2d(self.n2, self.n3, kernel=param_dict['conv.6.weight'], padding=2, stride=1)\n",
    "\n",
    "        # self.n4 = pb.LIF((channels*8, 8, 8), bias=param_dict['conv.8.bias'], threshold=param_dict['conv.8.vthr'], reset_v=0, tick_wait_start=5) # convpool3x3\n",
    "        # self.conv2d_4 = pb.Conv2d(self.n3, self.n4, kernel=param_dict['conv.8.weight'], padding=2, stride=2)\n",
    "\n",
    "        # self.n5 = pb.LIF((channels*8, 8, 8), bias=param_dict['conv.10.bias'], threshold=param_dict['conv.10.vthr'], reset_v=0, tick_wait_start=6) # conv3x3\n",
    "        # self.conv2d_5 = pb.Conv2d(self.n4, self.n5, kernel=param_dict['conv.10.weight'], padding=2, stride=1)\n",
    "\n",
    "        self.n10 = pb.LIF(channels*8 * 8 * 8, threshold=param_dict['fc.2.vthr'], reset_v=0, tick_wait_start=5) # fc\n",
    "        self.fc_0 = pb.FullConn(self.n3, self.n10, conn_type=pb.SynConnType.All2All, weights=param_dict['fc.2.weight'])\n",
    "\n",
    "        self.n11 = pb.LIF(channels*8 * 4 * 4, threshold=param_dict['fc.5.vthr'], reset_v=0, tick_wait_start=6) # fc\n",
    "        self.fc_1 = pb.FullConn(self.n10, self.n11, conn_type=pb.SynConnType.All2All, weights=param_dict['fc.5.weight'])\n",
    "\n",
    "        self.n12 = pb.LIF(80, threshold=param_dict['fc.8.vthr'], reset_v=0, tick_wait_start=7) # fc\n",
    "        self.fc_2 = pb.FullConn(self.n11, self.n12, conn_type=pb.SynConnType.All2All, weights=param_dict['fc.8.weight'])\n",
    "\n",
    "        self.probe1 = pb.Probe(self.n12, \"spike\")\n",
    "\n",
    "C = 2\n",
    "\n",
    "# PAIBox网络初始化\n",
    "param_dict = {}\n",
    "def getNetParam():\n",
    "    timestep = 8\n",
    "    layer_num = 9\n",
    "    delay = layer_num - 1\n",
    "    param_dict[\"timestep\"] = timestep\n",
    "    param_dict[\"layer_num\"] = layer_num\n",
    "    param_dict[\"delay\"] = delay\n",
    "\n",
    "    param_dict['conv.0.weight']=np.random.randint(1,127,size=(C*2,2,5,5))\n",
    "    param_dict['conv.0.bias']=np.random.randint(1,127,size=(C*2))\n",
    "    param_dict['conv.2.weight']=np.random.randint(1,127,size=(C*2,C*2,5,5))\n",
    "    param_dict['conv.2.bias']=np.random.randint(1,127,size=(C*2))\n",
    "    param_dict['conv.4.weight']=np.random.randint(1,127,size=(C*4,C*2,5,5))\n",
    "    param_dict['conv.4.bias']=np.random.randint(1,127,size=(C*4))\n",
    "    param_dict['conv.6.weight']=np.random.randint(1,127,size=(C*4,C*4,5,5))\n",
    "    param_dict['conv.6.bias']=np.random.randint(1,127,size=(C*4))\n",
    "    param_dict['conv.8.weight']=np.random.randint(1,127,size=(C*8,C*4,5,5))\n",
    "    param_dict['conv.8.bias']=np.random.randint(1,127,size=(C*8))\n",
    "    param_dict['conv.10.weight']=np.random.randint(1,127,size=(C*8,C*8,5,5))\n",
    "    param_dict['conv.10.bias']=np.random.randint(1,127,size=(C*8))\n",
    "    param_dict['fc.2.weight']=np.random.randint(1,127,size=(C*8*8*8,C*4*18*13)).T\n",
    "    param_dict['fc.5.weight']=np.random.randint(1,127,size=(C*8*4*4,C*8*8*8)).T\n",
    "    param_dict['fc.8.weight']=np.random.randint(1,127,size=(80,C*8*4*4)).T\n",
    "    param_dict['conv.0.vthr']=10\n",
    "    param_dict['conv.2.vthr']=20\n",
    "    param_dict['conv.4.vthr']=30\n",
    "    param_dict['conv.6.vthr']=40\n",
    "    param_dict['conv.8.vthr']=50\n",
    "    param_dict['conv.10.vthr']=60\n",
    "    param_dict['fc.2.vthr']=70\n",
    "    param_dict['fc.5.vthr']=80\n",
    "    param_dict['fc.8.vthr']=90\n",
    "getNetParam()\n",
    "\n",
    "# PAIBox仿真器\n",
    "pb_net = Conv2d_Net(C, param_dict)\n",
    "sim = pb.Simulator(pb_net)\n",
    "\n",
    "\n",
    "# test(test_num=50)\n",
    "pb.BACKEND_CONFIG.target_chip_addr = (0, 0)\n",
    "\n",
    "# print(pb_net.conv2d_0.name)\n",
    "# print(type(pb_net.n0))\n",
    "# print(pb_net.n0.shape_in)\n",
    "# print(pb_net.n0.shape_out)\n",
    "# print(type(pb_net.n0[0,:,:]))\n",
    "# print(pb_net.n0[0,:,:].shape_in)\n",
    "# print(pb_net.n0[0,:,:].shape_out)\n",
    "# n1_0_1 = (pb_net.n11,pb_net.n11)\n",
    "# print(type(n1_0_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core required: 897\n"
     ]
    }
   ],
   "source": [
    "mapper = pb.Mapper()\n",
    "\n",
    "mapper.build(pb_net)\n",
    "\n",
    "# Core estimate only\n",
    "graph_info = mapper.compile(\n",
    "    weight_bit_optimization=True, grouping_optim_target=\"both\", core_estimate_only=True\n",
    ")\n",
    "\n",
    "# #N of cores required\n",
    "print(\"Core required:\", graph_info[\"n_core_required\"])\n",
    "\n",
    "# Clear all the results\n",
    "mapper.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Core required: 897\n"
     ]
    }
   ],
   "source": [
    "mapper = pb.Mapper()\n",
    "\n",
    "mapper.build(pb_net)\n",
    "\n",
    "graph_info = mapper.compile(\n",
    "    weight_bit_optimization=True, grouping_optim_target=\"both\"\n",
    ")\n",
    "\n",
    "# #N of cores required\n",
    "print(\"Core required:\", graph_info[\"n_core_required\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper.export(\n",
    "    write_to_file=True, fp=\"./debug\", format=\"npy\", export_core_params=False\n",
    ")\n",
    "\n",
    "# Clear all the results\n",
    "mapper.clear()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
